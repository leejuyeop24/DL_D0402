{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [ CNN Fashion MNIST MODEL]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] 모듈 로딩 및 데이터 준비<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 모듈 로딩\n",
    "import torch                                        ## Tensor 및 기본 함수들 관련 모듈\n",
    "import torch.nn as nn                               ## 인공신경망 관련 모듈\n",
    "import torch.nn.functional as F                     ## 인공신경망 관련 함수들 모듈 \n",
    "\n",
    "from torchvision.datasets import FashionMNIST       ## 비젼관련 내장 데이터셋 모듈\n",
    "from torch.utils.data import DataLoader             ## Pytorch의 데이터셋 관련 모듈\n",
    "\n",
    "import torchvision.transforms as transforms         ## 비젼관련 이미지 증강/변환 관련 모듈\n",
    "\n",
    "import matplotlib.pyplot as plt                     ## 이미지 시각화 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 이미지 관련 준비\n",
    "IMG_ROOT = '../data/image/'                         ## 이미지 데이터 저장 폴더 경로"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] 데이터 로딩 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDS=FashionMNIST(root=IMG_ROOT,\n",
    "                     download=True,\n",
    "                     train=True,\n",
    "                     transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDS=FashionMNIST(root=IMG_ROOT,\n",
    "                     download=True,\n",
    "                     train=False, \n",
    "                     transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type         : <class 'torchvision.datasets.mnist.FashionMNIST'>\n",
      "\n",
      "classes      : ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
      "\n",
      "class_to_idx : {'T-shirt/top': 0, 'Trouser': 1, 'Pullover': 2, 'Dress': 3, 'Coat': 4, 'Sandal': 5, 'Shirt': 6, 'Sneaker': 7, 'Bag': 8, 'Ankle boot': 9}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 데이터셋 체크\n",
    "## - 타입\n",
    "print(f'type         : {type(testDS)}\\n')\n",
    "\n",
    "## - 속성 : 클래스 정보\n",
    "print(f'classes      : {testDS.classes}\\n')\n",
    "print(f'class_to_idx : {testDS.class_to_idx}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets      : tensor([9, 2, 1,  ..., 8, 1, 5])\n",
      "\n",
      "data         : torch.Size([10000, 28, 28])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## - 속성 : 데이터와 타겟\n",
    "print(f'targets      : {testDS.targets}\\n')\n",
    "print(f'data         : {testDS.data.shape}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 이미지 데이터와 타겟 확인\n",
    "idx_to_classes ={v:k for k, v in testDS.class_to_idx.items()}\n",
    "\n",
    "plt.imshow(testDS.data[0], cmap='gray')\n",
    "plt.title(idx_to_classes[testDS.targets[0].item()])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Image Data : 0, 255\n"
     ]
    }
   ],
   "source": [
    "## 로우 데이터 확인\n",
    "print(f'Raw Image Data : {testDS.data[0].min()}, {testDS.data[0].max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3] 모델 정의 및 설계 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DNN MODEL -----------------------------------------------------------------------\n",
    "## 클래스이름 : FashionDNN\n",
    "## 부모클래스 : nn.Module\n",
    "## 모델구현법 : 지도학습 + 다중 분류 \n",
    "## 모델층 구성  입력피쳐/신호     출력/퍼셉트론수    활성화함수\n",
    "## 입  력  층       784             512             ReLu\n",
    "## 은  닉  층       512             256             ReLu\n",
    "## 은  닉  층       256             130             ReLu\n",
    "## 출  력  층       130             10               X\n",
    "## ----------------------------------84----------------------------------------------\n",
    "class FashionDNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.in_layer   = nn.Flatten()\n",
    "        self.hd_layer1  = nn.Linear(784, 512)\n",
    "        self.drop_layer = nn.Dropout(0.25)\n",
    "        self.hd_layer2  = nn.Linear(512, 256)\n",
    "        self.hd_layer3  = nn.Linear(256, 130)\n",
    "        self.out_layer  = nn.Linear(130, 10)\n",
    "        \n",
    "    ## 순방향 학습 진행 메서드 \n",
    "    def forward(self, data):\n",
    "        ## 3D (BS, H, W) ==> 2D (BS, H*W)\n",
    "        print(f'data shape : {data.shape}')\n",
    "        out = self.in_layer(data)\n",
    "        print(f'out shape : {out.shape}')\n",
    "\n",
    "        out =F.relu(self.hd_layer1(out))\n",
    "        out = self.drop_layer(out)\n",
    "\n",
    "        out =F.relu(self.hd_layer2(out))\n",
    "        out = self.drop_layer(out)\n",
    "\n",
    "        out =F.relu(self.hd_layer3(out))\n",
    "        out = self.out_layer(out)\n",
    "        \n",
    "        print(f'out shape : {out.shape}')\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape : torch.Size([100, 28, 28])\n",
      "out shape : torch.Size([100, 784])\n",
      "out shape : torch.Size([100, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "FashionDNN                               [100, 10]                 --\n",
       "├─Flatten: 1-1                           [100, 784]                --\n",
       "├─Linear: 1-2                            [100, 512]                401,920\n",
       "├─Dropout: 1-3                           [100, 512]                --\n",
       "├─Linear: 1-4                            [100, 256]                131,328\n",
       "├─Dropout: 1-5                           [100, 256]                --\n",
       "├─Linear: 1-6                            [100, 130]                33,410\n",
       "├─Linear: 1-7                            [100, 10]                 1,310\n",
       "==========================================================================================\n",
       "Total params: 567,968\n",
       "Trainable params: 567,968\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 56.80\n",
       "==========================================================================================\n",
       "Input size (MB): 0.31\n",
       "Forward/backward pass size (MB): 0.73\n",
       "Params size (MB): 2.27\n",
       "Estimated Total Size (MB): 3.31\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 모델 구조 확인 \n",
    "from torchinfo import summary \n",
    "\n",
    "m1 = FashionDNN()\n",
    "summary(m1, input_size=(100, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape : torch.Size([2, 28, 28])\n",
      "out shape : torch.Size([2, 784])\n",
      "out shape : torch.Size([2, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ -7.4425,   6.9412,  -4.5538,  -8.2950, -13.4516,  -2.1559,   9.8656,\n",
       "           -3.6305,  -5.0619, -12.4136],\n",
       "         [ -9.9866,  11.5438,   2.4364,  -7.1637,  -7.3627,  -3.1741,  12.7201,\n",
       "           -1.9780,   2.3185,  -9.6685]], grad_fn=<AddmmBackward0>),\n",
       " tensor([9, 0]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## DNN모델에 이미지 테스트\n",
    "testImg = trainDS.data[0:2].float()\n",
    "pre=m1(testImg)\n",
    "pre, trainDS.targets[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CNN MODEL -----------------------------------------------------------------------\n",
    "## 클래스이름 : FashionCNN\n",
    "## 부모클래스 : nn.Module\n",
    "## 모델구현법 : 지도학습 + 다중 분류 \n",
    "## 모델층 구성  \n",
    "## 특징  추출  입력 이미지 주요 특징 추출한 특징맵 FeatureMap\n",
    "## 합성 곱 층  이미지채널/커널수    출력채널/커널수   커널크기  패딩크기   스트라이드  \n",
    "##                 1                1              3        0          1 \n",
    "## 풀  링  층  커널크기,   스트라이드\n",
    "##                2          2\n",
    "## 플  랫  층   --    \n",
    "##\n",
    "## 전결합학습  추출된 FeatureMap으로 학습 진행\n",
    "## 은  닉  층  커널수*높이*너비     출력/퍼셉트론수 \n",
    "##                                   30\n",
    "## 은  닉  층        30               15\n",
    "## 출  력  층        15               10\n",
    "## --------------------------------------------------------------------------------\n",
    "class FashionCNN0(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        ## 특징맵 추출 부분\n",
    "        self.con_layer1 = nn.Conv2d(1, 1, 3)     ## (1, 1, 28, 28 )  ==> (1,  1, 26, 26)\n",
    "        self.pool_layer1= nn.MaxPool2d(2, 2)     ## (1, 1, 26, 26 )  ==> (1,  1, 13, 13)\n",
    "        self.flat_layer = nn.Flatten()           ## (1, 1, 13, 13)   ==> (1,  1*13*13)\n",
    "\n",
    "        ## 전결합 학습 부분\n",
    "        self.fc_layer  = nn.Linear(169, 30)     \n",
    "        self.out_layer = nn.Linear(30, 10)\n",
    "\n",
    "\n",
    "    def forward(self, data):\n",
    "        print(f'IN data shape     : {data.shape}')\n",
    "        out = F.relu(self.con_layer1(data))\n",
    "        print(f'con_layer1 shape  : {out.shape}')\n",
    "        out = self.pool_layer1(out)\n",
    "        print(f'pool_layer1 shape : {out.shape}')\n",
    "\n",
    "        out = self.flat_layer(out)\n",
    "        print(f'flatten_layer shape : {out.shape}')\n",
    "        \n",
    "        out =F.relu(self.fc_layer(out))\n",
    "        out = self.out_layer(out)\n",
    "        print(f'out_layer shape : {out.shape}')\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN data shape     : torch.Size([1, 28, 28])\n",
      "con_layer1 shape  : torch.Size([1, 26, 26])\n",
      "pool_layer1 shape : torch.Size([1, 13, 13])\n",
      "flatten_layer shape : torch.Size([1, 169])\n",
      "out_layer shape : torch.Size([1, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "FashionCNN0                              [1, 10]                   --\n",
       "├─Conv2d: 1-1                            [1, 26, 26]               10\n",
       "├─MaxPool2d: 1-2                         [1, 13, 13]               --\n",
       "├─Flatten: 1-3                           [1, 169]                  --\n",
       "├─Linear: 1-4                            [1, 30]                   5,100\n",
       "├─Linear: 1-5                            [1, 10]                   310\n",
       "==========================================================================================\n",
       "Total params: 5,420\n",
       "Trainable params: 5,420\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.01\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.01\n",
       "Params size (MB): 0.02\n",
       "Estimated Total Size (MB): 0.03\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 모델 설계 및 정의 체크 \n",
    "m1 = FashionCNN0()\n",
    "summary(m1, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CNN MODEL -----------------------------------------------------------------------\n",
    "## 클래스이름 : FashionCNN\n",
    "## 부모클래스 : nn.Module\n",
    "## 모델구현법 : 지도학습 + 다중 분류 \n",
    "## 모델층 구성  입력피쳐/신호     출력/퍼셉트론수    활성화함수\n",
    "## 입  력  층       784             512             ReLu\n",
    "## 은  닉  층       512             256             ReLu\n",
    "## 은  닉  층       256             130             ReLu\n",
    "## 출  력  층       130             10               X\n",
    "## --------------------------------------------------------------------------------\n",
    "class FashionCNN1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.con_layer1     = nn.Conv2d(1, 1, 3, padding=1)\n",
    "        self.pool_layer1    = nn.MaxPool2d(2)\n",
    "        self.con_layer2     = nn.Conv2d(1, 1, 3)\n",
    "        self.pool_layer2    = nn.MaxPool2d(2)\n",
    "        self.flatten_layer  = nn.Flatten()\n",
    "        self.fc_layer       = nn.Linear(1*6*6, 30)\n",
    "        self.out_layer      = nn.Linear(30, 10)\n",
    "        \n",
    "\n",
    "    def forward(self, data):\n",
    "        print(f'data shape : {data.shape}')\n",
    "\n",
    "        out = F.relu(self.con_layer1(data))\n",
    "        print(f'1. out shape : {out.shape}')\n",
    "        out = self.pool_layer1(out)\n",
    "        print(f'1-1. out shape : {out.shape}')\n",
    "        \n",
    "        out = F.relu(self.con_layer2(out))\n",
    "        print(f'2. out shape : {out.shape}')\n",
    "        out = self.pool_layer2(out)\n",
    "        print(f'2-1. out shape : {out.shape}')\n",
    "\n",
    "        out = self.flatten_layer(out)\n",
    "        print(f'3. out shape : {out.shape}')\n",
    "        \n",
    "        out =F.relu(self.fc_layer(out))\n",
    "        out = self.out_layer(out)\n",
    "        print(f'out shape : {out.shape}')\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape : torch.Size([1, 28, 28])\n",
      "1. out shape : torch.Size([1, 28, 28])\n",
      "1-1. out shape : torch.Size([1, 14, 14])\n",
      "2. out shape : torch.Size([1, 12, 12])\n",
      "2-1. out shape : torch.Size([1, 6, 6])\n",
      "3. out shape : torch.Size([1, 36])\n",
      "out shape : torch.Size([1, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "FashionCNN1                              [1, 10]                   --\n",
       "├─Conv2d: 1-1                            [1, 28, 28]               10\n",
       "├─MaxPool2d: 1-2                         [1, 14, 14]               --\n",
       "├─Conv2d: 1-3                            [1, 12, 12]               10\n",
       "├─MaxPool2d: 1-4                         [1, 6, 6]                 --\n",
       "├─Flatten: 1-5                           [1, 36]                   --\n",
       "├─Linear: 1-6                            [1, 30]                   1,110\n",
       "├─Linear: 1-7                            [1, 10]                   310\n",
       "==========================================================================================\n",
       "Total params: 1,440\n",
       "Trainable params: 1,440\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.01\n",
       "Params size (MB): 0.01\n",
       "Estimated Total Size (MB): 0.02\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 모델 설계 및 정의 체크 \n",
    "m1 = FashionCNN1()\n",
    "summary(m1, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) 9\n",
      "data shape : torch.Size([1, 28, 28])\n",
      "1. out shape : torch.Size([1, 28, 28])\n",
      "1-1. out shape : torch.Size([1, 14, 14])\n",
      "2. out shape : torch.Size([1, 12, 12])\n",
      "2-1. out shape : torch.Size([1, 6, 6])\n",
      "3. out shape : torch.Size([1, 36])\n",
      "out shape : torch.Size([1, 10])\n",
      "tensor([[-0.1069,  0.1041,  0.0891, -0.0071,  0.0448, -0.1591, -0.1054, -0.0290,\n",
      "          0.0695, -0.1345]], grad_fn=<AddmmBackward0>) 9\n"
     ]
    }
   ],
   "source": [
    "## 모델 이미지 적용 후 체크\n",
    "for img, target in testDS:\n",
    "    print(img.shape, target)\n",
    "    pre = m1(img)\n",
    "    print(pre, target)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_TORCH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
